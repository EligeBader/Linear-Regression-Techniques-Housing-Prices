{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this notebook, I performed data preprocessing, feature engineering, and model predictions for housing prices using various machine learning models. The purpose of this notebook is to predict the sale prices of houses based on the given features in the dataset. We utilized RandomForest, XGBRegressor, and a Neural Network model to make predictions, demonstrating the application of different regression techniques to improve the accuracy of our predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUnrrUHBsbMW"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U5P1JhqUiSwi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import dill\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import TargetEncoder\n",
        "import os\n",
        "from define_function import *\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYapb-fNsdk_"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Uc3RWc5kiSwk"
      },
      "outputs": [],
      "source": [
        "df_test = load_data('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1Yxi07GQiSwk"
      },
      "outputs": [],
      "source": [
        "# Assign the ID feature to a variable so I can use it later for the submission file\n",
        "id_test = df_test['Id']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miayblUdse-g"
      },
      "source": [
        "# drop features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kEM0-2VDiSwk"
      },
      "outputs": [],
      "source": [
        "# drop uneeded features\n",
        "df_test = drop_features(df_test, features_to_drop=['Alley','PoolQC','Fence','MiscFeature'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltrlda4FshBe"
      },
      "source": [
        "# Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEOIul_jiSwl",
        "outputId": "58a7d231-21c5-4216-ec74-bcea390ab339"
      },
      "outputs": [],
      "source": [
        "# Impute data to fill missing values\n",
        "df_test = clean_data(df_test, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E76uteuiSwl",
        "outputId": "bb1d6752-c7f5-427c-b2c5-f2e734335ee8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check if there are any missing values\n",
        "df_test.isna().sum().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTXaMZBdsigx"
      },
      "source": [
        "# Encode Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzjB1OwEiSwl",
        "outputId": "fa408b37-ce10-4f15-ac7b-f13749e0098f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'target': TargetEncoder(target_type='continuous'), 'ordinal': OrdinalEncoder()}\n"
          ]
        }
      ],
      "source": [
        "# Encode data to numerical values\n",
        "Target_Encoding_list = ['MSZoning', 'Street', 'Utilities', 'LotConfig', 'Neighborhood', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'CentralAir', 'Electrical', 'GarageType', 'SaleType']\n",
        "Ordinal_Encoding_list= ['LotShape', 'LandContour', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'HeatingQC', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'SaleCondition']\n",
        "\n",
        "\n",
        "encoding_methods = {col: 'target' for col in Target_Encoding_list}\n",
        "encoding_methods.update({col: 'ordinal' for col in Ordinal_Encoding_list})\n",
        "\n",
        "df_test = encode_data(df_test, encoding_methods , train=False, target=['SalePrice'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSccfbOGskvc"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomForest Model Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-WP_3hviSwm",
        "outputId": "719c51f9-7ef8-488d-859b-1b8ecfa73942"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions after inverse transform (if applicable):[123611.20879274 149861.00548954 183461.9437456  ... 158309.59441399\n",
            " 123880.77147012 218220.25182775]\n"
          ]
        }
      ],
      "source": [
        "# load model and feature list\n",
        "with open('trained_model_rf.pickle', 'rb') as f:\n",
        "    trained_model_rf = dill.load(f)\n",
        "\n",
        "\n",
        "with open('feature_list.pickle', 'rb') as f:\n",
        "    train_columns = dill.load(f)\n",
        "\n",
        "\n",
        "# select only the features used in training\n",
        "df_test = df_test[train_columns]\n",
        "for col in train_columns:\n",
        "    df_test[col] = df_test[col].astype(float)\n",
        "\n",
        "\n",
        "# predict the target variable\n",
        "y_new_pred_rf = predict_model(df_test, trained_model_rf)\n",
        "y_new_pred_rf = y_new_pred_rf.flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### XgbRegressor Model Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions after inverse transform (if applicable):[124631.555 154569.89  183071.38  ... 161633.47  122293.664 203357.47 ]\n"
          ]
        }
      ],
      "source": [
        "# load model and feature list\n",
        "with open('trained_model_XG.pickle', 'rb') as f:\n",
        "    trained_model_XG = dill.load(f)\n",
        "\n",
        "\n",
        "with open('feature_list.pickle', 'rb') as f:\n",
        "    train_columns = dill.load(f)\n",
        "\n",
        "# select only the features used in training\n",
        "df_test = df_test[train_columns]\n",
        "for col in train_columns:\n",
        "    df_test[col] = df_test[col].astype(float)\n",
        "\n",
        "\n",
        "# predict the target variable\n",
        "y_new_pred_XG = predict_model(df_test, trained_model_XG)\n",
        "y_new_pred_XG = y_new_pred_XG.flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Neural Network Model PRedictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFK453CY3smk",
        "outputId": "ddb1fcc7-8084-407f-f5aa-b2bc186aa196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
            "Inverse transform produced NaNs. Returning raw predictions.\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step\n",
            "Predictions after inverse transform (if applicable):[[142586.19]\n",
            " [162550.73]\n",
            " [217901.25]\n",
            " ...\n",
            " [154674.  ]\n",
            " [180399.66]\n",
            " [159724.95]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[142586.19],\n",
              "       [162550.73],\n",
              "       [217901.25],\n",
              "       ...,\n",
              "       [154674.  ],\n",
              "       [180399.66],\n",
              "       [159724.95]], dtype=float32)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load model\n",
        "with open('trained_nn_model.pickle', 'rb') as f:\n",
        "    trained_nn_model = dill.load(f)\n",
        "\n",
        "\n",
        "# predict the target variable\n",
        "y_new_pred_nn = predict_model(df_test, trained_nn_model)\n",
        "y_new_pred_nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save predictions with corresponding IDs for the random forest model\n",
        "model_rf = pd.DataFrame({'Id': id_test, 'SalePrice': y_new_pred_rf})\n",
        "model_rf.to_csv('prediction_rf.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save predictions with corresponding IDs for the XGBRegressor model\n",
        "model_xg = pd.DataFrame({'Id': id_test, 'SalePrice': y_new_pred_XG})\n",
        "model_xg.to_csv('prediction_xg.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save predictions with corresponding IDsvfor the neural network model\n",
        "model_nn = pd.DataFrame({'Id': id_test, 'SalePrice': y_new_pred_nn.flatten()})\n",
        "model_nn.to_csv('prediction_nn.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bUnrrUHBsbMW",
        "AYapb-fNsdk_",
        "miayblUdse-g",
        "ltrlda4FshBe",
        "DTXaMZBdsigx"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
